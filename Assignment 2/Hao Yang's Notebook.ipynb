{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e96768-742a-41a8-a8fe-4fe2a469c2f5",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\"><b>DSA312 Data Science with Python</b></p>\n",
    "<p style=\"text-align: center;\"><b>Author: Jing Rong GOH</b></p>\n",
    "<p style=\"text-align: center;\"><b>Assignment 2</b></p>\n",
    "<p style=\"text-align: center;\"><b>Note: This assignment has 7 questions (Q1-Q5 are 10 marks each, Q6-Q7 are 5 marks each)</b></p>\n",
    "<p style=\"text-align: center;\"><b>Note: Points may be deducted for overly verbose or inefficient code. Bonus credit will be awarded for concise and elegant solutions.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92ef0a-be60-4543-99dc-eb0bfc54e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e691d7c-63ff-4d7c-b5af-954550acd97c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q1\n",
    "Using the Breast Cancer dataset (`load_breast_cancer`) from `sklearn.datasets`, perform a logistic regression (without regularization) to predict whether a tumor is benign or malignant (`target`) based on the features: `mean radius`, `mean texture`, and `mean perimeter`. Where necessary, set seed values and/or random_state to `1`; set max_iter=`10000`.\n",
    "\n",
    "##### (a) Use the model specification above to fit the entire Breast Cancer dataset. Using the fitted model, get the corresponding predicted `target` values and subsequently generate the confusion matrix. From the Confusion Matrix, report the True Positive, True Negative, False Positive and False Negative values.\n",
    "##### (b) Use the values from the confusion matrix in `Q1a` to calculate the F1 score manually using the F1 Score formula. In addition, use an appropriate function from `sklearn` to compute the corresponding F1 score. Compare the two calculated F1 scores. Are they the same or different? Explain why.\n",
    "##### (c) Use a validation approach where 70% of the data is used for training and 30% is used for validation. Fit the logistic regression model (without regularization) using the training set. Calculate and report the F1-score on the validation set.\n",
    "##### (d) Fit a Lasso Logistic Regression model (L1 regularization) with a penalty of `C = 0.6`. What is the F1 Score of the Lasso Logistic Regression model on the validation set?\n",
    "##### (e) Based on the F1 Scores, which model (with or without regularization) performs better on the validation set?\n",
    "##### (f) For the Lasso Logistic Regression model (L1 regularization), change the penalty to `C = 1e99`. What do you expect the resulting F1 Score to be on the validation set? Is the actual result aligned with your expectation? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e633b-0eb0-409e-97a8-b8a009b2bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "# Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7657970-71aa-4873-922c-636ba964b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1a\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa30703-c920-42ff-9549-3ab02963e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1b\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fb59b-8048-4090-8e92-117878e2ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1c\n",
    "\n",
    "# Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1058d-f7b3-4b81-af74-b1d47266816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1d\n",
    "\n",
    "# Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d1e07-ced7-407e-81ab-76a76db8d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1e\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015edd95-82f6-4b37-badc-329835142218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1f\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c750d17-2d5c-479a-8f5e-ca60af0eb785",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q2\n",
    "Use the California housing dataset (`fetch_california_housing`) from `sklearn.datasets` for this question, the objective is to predict the median house price `target` based on all available features in the dataset. Where necessary, set seed values and/or random_state to `1`. Where applicable, MSE is to be calculated using the default formula (i.e. not regression formula) to evaluate model's performance, unless otherwise stated.\n",
    "##### (a) Use the entire dataset to generate a simple decision tree with a maximum depth of 3. Visualize the tree structure and its decision boundaries.\n",
    "##### (b) Using the decision tree from `Q2a`, state the average value of the median house price in the dataset.\n",
    "##### (c) Using the decision tree from `Q2a`, calculate the Sum Squared Residuals (SSR) at the root node (i.e. top node). Calculate the Sum Squared Residuals (SSR) at the leaf nodes (i.e. terminal nodes). Calculate the corresponding percentage reduction in SSR between the root and leaf nodes.\n",
    "##### (d) Given a dummy observation with following feature values: `{'target': 2.0, 'MedInc': 5.0, 'HouseAge': 25, 'AveRooms': 6.0, 'AveBedrms': 1.1, 'Population': 1500, 'AveOccup': 3.0, 'Latitude': 34.05, 'Longitude': -118.25}`. Use the decision tree from `Q2a` to get the predicted value for the dummy observation, and calculate the corresponding loss function (i.e. Mean Squared Error) for this dummy observation.\n",
    "##### (e) Use a validation approach where 70% of the data is used for training and 30% is used for validation. Fit a full decision tree (i.e. no need to set `max_depth`) on the training data. Calculate and report the MSE on the validation set.\n",
    "##### (f) Use a validation approach where 70% of the data is used for training and 30% is used for validation. Perform Bagging (using 200 trees) on the training data. Calculate and report the MSE on the validation set.\n",
    "##### (g) Use a validation approach where 70% of the data is used for training and 30% is used for validation. Perform Random Forest (using 200 trees) on the training data. Calculate and report the MSE on the validation set.\n",
    "##### (h) Which model above is the best? Why? What is the most important feature in this best model?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a443a-d3c3-4647-85b8-e4ecf0a8cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Load Libraries Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83593b-3103-4cb8-a633-46adc4e147dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a051d-5be7-4154-9379-33a3b5d3e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2b\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1998177-07e6-4f0c-becd-8142eba50459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2c\n",
    "\n",
    "# Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c63b1d-6864-4c61-b3cf-6560a9afac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2d\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68309233-8694-456b-a8f9-d88f364ccf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2e\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c26c20-6fda-4feb-82da-b4e5e81f2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2f\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccb34b-ea42-4ef4-90b8-9ba1e49bcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2g\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2fe5d-e274-45b9-a99c-0b8d5bca2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2h\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13e006a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q3\n",
    "Use the California housing dataset (`fetch_california_housing`) from `sklearn.datasets` for this question, the objective is to predict the median house price `target` based on all available features in the dataset. Where necessary, set seed values and/or random_state to `8`. Where applicable, ensure the data is suitably standardized. Where applicable, MSE is to be calculated using the default formula (i.e. not regression formula) to evaluate model's performance, unless otherwise stated.\n",
    "\n",
    "##### (a) Perform a K-Nearest Neighbors (KNN) regression on the entire dataset using `K=3` and report the corresponding MSE.\n",
    "##### (b) Given a dummy observation with following feature values: `{'target': 2.0, 'MedInc': 5.0, 'HouseAge': 25, 'AveRooms': 6.0, 'AveBedrms': 1.1, 'Population': 1500, 'AveOccup': 3.0, 'Latitude': 34.05, 'Longitude': -118.25}`. Use the fitted KNN regression from `Q3a` to get the predicted value for the dummy observation, and calculate the corresponding loss function (i.e. Mean Squared Error) for this dummy observation.\n",
    "##### (c) Use a validation approach where 70% of the data is used for training and 30% is used for validation. Perform a KNN regression using `K=3` on the training data. Calculate and report the MSE on the validation set.\n",
    "##### (d) Perform hyperparameter tuning to find the optimal value of K for KNN, using K values ranging from 1 to 20, with 5-folds cross validation strategy. Report the optimal K and the corresponding cross-validated MSE. Fit the optimal KNN model on the training data and report the MSE on the validation set.\n",
    "##### (e) Refit the optimal KNN model using the entire dataset and report the corresponding MSE.\n",
    "##### (f) Given a dummy observation with following feature values: `{'target': 2.0, 'MedInc': 5.0, 'HouseAge': 25, 'AveRooms': 6.0, 'AveBedrms': 1.1, 'Population': 1500, 'AveOccup': 3.0, 'Latitude': 34.05, 'Longitude': -118.25}`. Use the fitted optimal KNN regression from `Q3e` to get the predicted value for the dummy observation, and calculate the corresponding loss function (i.e. Mean Squared Error) for this dummy observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f57f65-b41f-45fc-a2f7-d711472c2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 Load Libraries Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0da268-4457-4c64-90ec-c0d085a323c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3a\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b0c91-ce06-4075-825a-a20c6f1479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3b\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eac584-4943-4c9e-b14c-22259134c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3c\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4233e4-44fc-4af5-ab1f-1f130213774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3d\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ef17b-1b42-4775-ae89-b1ad1fc2a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3e\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5500e37-2490-4087-923d-a08a1f113d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3f\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42794be-6ce3-44c3-a045-aca3970a3256",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q4.\n",
    "Use the Wine dataset (`load_wine`) from `sklearn.datasets` for this question, where the objective is to perform Principal Component Analysis (PCA) on the dataset containing 13 features (i.e., chemical properties of different wines). Where applicable, ensure the data is suitably standardized.\n",
    "##### (a) Perform PCA on the standardized wine dataset using all available features. How many Principal Components are generated? \n",
    "##### (b) What is the eigenvector for the Second Principal Component?\n",
    "##### (c) State the loading scores for the Second Principal Component in simple English.\n",
    "##### (d) Which feature is the most important in influencing the Second Principal Component? Explain your answer.\n",
    "##### (e) Report the Principal Component scores for the first three observations projected onto the 2nd PC.\n",
    "##### (f) What is the eigenvalue for the Second Principal Component?\n",
    "##### (g) What is the proportion of total variation explained by the Second Principal Component?\n",
    "##### (h) Generate a scree plot with appropriate titles and axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3160cc-a70e-4065-a9bb-4e18a37375af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 Load Libraries Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d4d5b-076e-42b2-8253-c9f133a64836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4a.\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b2d72-c26b-49bd-b7d2-36792f81ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4b.\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85cd9f1-f628-4a5c-818f-10e72055e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4c\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf18df-6645-4808-95ee-21f5ee914acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4d\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468fef9-2c31-4195-a16a-d318919af863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4e\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c6575-cc57-4bd6-8838-e6e2ba5a5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4f\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1cd0e-ff9a-496c-b396-1ce86539bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4g\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02980463-e980-4c80-952b-69c08e9c61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4h\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38304a50-0122-4e8f-9413-681c59604802",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q5. \n",
    "Use the Diabetes dataset (`load_diabetes`) from `sklearn.datasets` for this question, where the objective is to predict the progression of the disease (`target`) based on all available features. Set all seed values and random_state to `1` for reproducibility where necessary. Where applicable, use `adam` as the optimizer, with a batch size of `32`, and epochs is `1000`. Where applicable, MSE is to be calculated using the default formula (i.e. not regression formula) to evaluate model's performance, unless otherwise stated. Where applicable for neural networks, ensure the data is suitably standardized.\n",
    "\n",
    "##### (a) Perform a multiple linear regression on the entire dataset. Report the Mean Squared Error (MSE).\n",
    "##### (b) Perform a multiple linear regression using 70% of the data for training and 30% for validation. Report the validation MSE.\n",
    "##### (c) Use a neural network structure with 2 hidden layers, with each layer having 2 hidden nodes with the softplus activation function; having one node in the output layer with the linear activation function. Fit the model on the entire dataset and report the MSE.\n",
    "##### (d) Using the same neural network architecture from `Q5c`, fit the model using 70% of the data for training and 30% for validation. Report the validation MSE.\n",
    "##### (e) Use a neural network structure with 64 nodes in the first hidden layer and 32 nodes in the second hidden layer (both using softplus); having one node in the output layer with the linear activation function. Fit the model on the entire dataset and report the MSE.\n",
    "##### (f) Using the same neural network architecture from `Q5e` but use 70% of the data for training and 30% for validation. Report the validation MSE.\n",
    "##### (g) Using the same neural network architecture from `Q5e` but change the activation function to relu. Report the MSE.\n",
    "##### (h) Using the same neural network architecture from `Q5g` but use 70% of the data for training and 30% for validation. Report the validation MSE.\n",
    "##### (i) Without further calculations, which model from `Q5a` to `Q5h` performs the best? Explain your answer.\n",
    "##### (j) Without further calculations, using the best model from `Q5i` to fit the entire dataset, what will the MSE be? Explain your answer.\n",
    "##### (k) Without further calculations, which model from `Q5a` to `Q5h` performs the worst? Explain your answer. Suggest the problem that is causing the poor performance and identify ways to improve performance of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc34a16-2f95-472e-9e53-c8c41fab6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 Load Libraries Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0819e81-bb14-4c13-9f56-5d619d803024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5a\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45d19b-3861-4196-aa7c-fd5c5a8f2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5b\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc192f6-bd74-4fd5-b839-982724596b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5c\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716f221-c842-4e1b-9a3e-eb0b1695b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5d\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e91a0-c2eb-46e3-8b4a-8a6b371af4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5e\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977eace-5821-41b0-b4e9-428b214bb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5f\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d77c11-bcf0-49d6-b9ce-3dfc6ee50ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5g\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b21c1-a6d4-4943-befd-df1f6f7910ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5h\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c5812-19a6-402a-af86-d570618d85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5i\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27eda2b-2efb-448e-b125-13fcc273c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5j\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f0582-8eae-4a09-bd29-cbadc3e35a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5k\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec362d7e-bb14-4d52-93a7-95197232e765",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q6.\n",
    "Developing effective practice questions and solutions is a key indicator of topic mastery. This question requires you to create an assignment question based on any materials covered in `Lectures 1 to 6` and provide a corresponding solution.\n",
    "\n",
    "Marks will be awarded based on following:\n",
    "  - Clarity: Ensure the question is clearly and concisely phrased, leaving no ambiguity for the student. \n",
    "  - Accuracy: The solution provided must be correct and aligned with the concepts taught in the lectures.\n",
    "  - Structured Solution: The solution must be well-structured, showing logical steps from problem statement to final answer.\n",
    "  - Relevance: The question must focus on topics covered in `Lectures 1 to 6`.\n",
    "  - Creativity: Questions should be novel and demonstrate depth in understanding. Avoid replicating questions shown in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b3441-f122-47fe-b5a5-c03531e488fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 Question here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad621470-e28e-4424-987d-b4f979d0607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4267f9a-a4a5-41e1-9960-00d969ddb428",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q7.\n",
    "Developing effective practice questions and solutions is a key indicator of topic mastery. This question requires you to create an assignment question based on any materials covered in `Lectures 7 to 12` and provide a corresponding solution.\n",
    "\n",
    "Marks will be awarded based on following:\n",
    "  - Clarity: Ensure the question is clearly and concisely phrased, leaving no ambiguity for the student. \n",
    "  - Accuracy: The solution provided must be correct and aligned with the concepts taught in the lectures.\n",
    "  - Structured Solution: The solution must be well-structured, showing logical steps from problem statement to final answer.\n",
    "  - Relevance: The question must focus on topics covered in `Lectures 7 to 12`.\n",
    "  - Creativity: Questions should be novel and demonstrate depth in understanding. Avoid replicating questions shown in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641fc99-0272-47c7-b6ed-47a012996482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 Question here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5630b83-b258-4d3a-ac99-8fe4ebdaa1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 Answer here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
